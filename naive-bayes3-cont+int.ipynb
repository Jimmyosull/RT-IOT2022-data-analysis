{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classification, with some code based on the tutorial from: \n",
    "https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from math import sqrt, exp, pi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data exists, download if required\n",
    "rt_iot2022 = fetch_ucirepo(id=942) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove axes that don't contribute to data, and get labels\n",
    "features = rt_iot2022.data.features\n",
    "targets = rt_iot2022.data.targets\n",
    "\n",
    "# get only continous or integer vars\n",
    "continuous_vars = rt_iot2022.variables[rt_iot2022.variables['type'] == \"Continuous\"]['name'].tolist()\n",
    "integer_vars = rt_iot2022.variables[rt_iot2022.variables['type'] == \"Integer\"]['name'].tolist()\n",
    "cont_int = continuous_vars + integer_vars\n",
    "# remove \"ID\", which is not a feature, and \"service\", which is non-numerical\n",
    "cont_int.remove('id')\n",
    "cont_int.remove('service')\n",
    "features = features[cont_int]\n",
    "\n",
    "# remove axes that are always the same\n",
    "# bwd_URG_flag count is always the same, usually removed\n",
    "unqi = features.nunique(axis=0)\n",
    "for i in range(len(unqi)):\n",
    "    if unqi[i] <= 1:\n",
    "        print(\"Removing\", features.axes[1][i])\n",
    "        del features[features.axes[1][i]]\n",
    "\n",
    "# Get labels for data (attack or normal behavior)\n",
    "normal_patterns = [\"MQTT_Publish\", \"Thing_speak\", \"Wipro_bulb_Dataset\", \"Amazon-Alexa\"]\n",
    "y_bool = [int(x in normal_patterns) for x in targets.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test sets\n",
    "X = features.values\n",
    "y = np.array(y_bool)\n",
    "np.random.seed(2)\n",
    "\n",
    "test_split = .2\n",
    "test_samples = int(len(X) * test_split)\n",
    "perm  = np.random.permutation(len(X))\n",
    "X = X[perm]\n",
    "y = y[perm]\n",
    "\n",
    "x_train = X[0:test_samples]\n",
    "y_train = y[0:test_samples]\n",
    "x_test  = X[test_samples:]\n",
    "y_test  = y[test_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate data by class\n",
    "def seperate_by_class(data, labels):\n",
    "    seperated = dict()\n",
    "    for i in range(len(data)):\n",
    "        vector = data[i]\n",
    "        if labels[i] not in seperated:\n",
    "            seperated[labels[i]] = list()    \n",
    "        seperated[labels[i]].append(vector)\n",
    "    return seperated\n",
    "\n",
    "seperated_train = seperate_by_class(x_train, y_train)\n",
    "seperated_test = seperate_by_class(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical measures\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stddev(numbers):\n",
    "    variance = sum([(x - mean(numbers))**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = []\n",
    "    for column in zip(*dataset):\n",
    "        # changed to numpy versions for efficency reasons (50 mins vs a few seconds)\n",
    "        column = np.array(column)\n",
    "        summaries.append([np.mean(column), np.std(column), len(column)])\n",
    "    return summaries\n",
    "\n",
    "# pass in the seperated dataset\n",
    "def summarize_classwise(dataset):\n",
    "    summaries = dict()\n",
    "    for classy, rows in dataset.items():\n",
    "        summaries[classy] = summarize(rows)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian prob dist calculation\n",
    "# TODO: why is std 0 sometimes\n",
    "def calc_prob(x, mean, std):\n",
    "    exponential = exp(-((x-mean)**2 / (2 * std**2)))\n",
    "    # if exponential == 0:\n",
    "    #     return 1e-10\n",
    "    return (1 / (sqrt(2 * pi) * std)) * exponential\n",
    "\n",
    "\n",
    "def calc_class_prob(summaries, row):\n",
    "    probs = dict()\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    for i, val in summaries.items():\n",
    "        probs[i] = summaries[i][0][2] / float(total_rows)\n",
    "        for j in range(len(val)):\n",
    "            mean, std, _ = val[j]\n",
    "            probs[i] *= calc_prob(row[j], mean, std)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_test = summarize_classwise(seperated_test)\n",
    "summarized_train = summarize_classwise(seperated_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98494, 80)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98493, 68)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all values with a standard deviation of zero in train\n",
    "std_zero = []\n",
    "for i in range(len(summarized_train[0])):\n",
    "    if summarized_train[0][i][1] == 0 or summarized_train[1][i][1] == 0:\n",
    "        std_zero.append(i)\n",
    "\n",
    "x_test = np.transpose(x_test)\n",
    "x_train = np.transpose(x_train)\n",
    "\n",
    "\n",
    "for i in reversed(range(len(std_zero))):\n",
    "    summarized_test[0].pop(std_zero[i])\n",
    "    summarized_test[1].pop(std_zero[i])\n",
    "    summarized_train[0].pop(std_zero[i])\n",
    "    summarized_train[1].pop(std_zero[i])\n",
    "    # TODO: remove from x_test\n",
    "    x_test = np.delete(x_test, std_zero[i], 0)\n",
    "    x_train = np.delete(x_train, std_zero[i], 0)\n",
    "\n",
    "x_test = np.transpose(x_test)\n",
    "x_train = np.transpose(x_train)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = calc_class_prob(summarized_train, x_train[15])\n",
    "\n",
    "predicted = []\n",
    "for i in x_test:\n",
    "    probs = calc_class_prob(summarized_train, i)\n",
    "    if probs[0] > probs[1]:\n",
    "        predicted.append(0)\n",
    "    else:\n",
    "        predicted.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes accuracy is: 0.9091204451077741\n",
      "Balanced Acc is:  0.49969683571793794\n"
     ]
    }
   ],
   "source": [
    "true_positive = 0\n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 1:\n",
    "        if predicted[i] == y_test[i]:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    elif predicted[i] == 0:\n",
    "        if predicted[i] == y_test[i]:\n",
    "            true_negative += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "\n",
    "pos_acc = true_positive / (true_positive + false_positive)\n",
    "neg_acc = true_negative / (true_negative + false_negative)\n",
    "\n",
    "print(\"Naive bayes accuracy is:\", (true_positive + true_negative)/len(predicted))\n",
    "print(\"Balanced Acc is: \", (pos_acc+neg_acc)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected  89342  attacks from  98493\n",
      "Incorrectly detected  3125  attacks from  98493\n",
      "Missed  5826  attacks from  98493\n",
      "Correctly asserted  200  packets as non harmful\n"
     ]
    }
   ],
   "source": [
    "print(\"Detected \", true_negative, \" attacks from \", len(predicted))\n",
    "print(\"Incorrectly detected \", false_negative, \" attacks from \", len(predicted))\n",
    "\n",
    "print(\"Missed \", false_positive, \" attacks from \", len(predicted))\n",
    "print(\"Correctly asserted \", true_positive, \" packets as non harmful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvpath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
