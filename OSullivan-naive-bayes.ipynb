{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classification, with some code based on the tutorial from: \n",
    "https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from math import sqrt, exp, pi\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Check if data exists, download if required\n",
    "# save to disk after download to speed up on between runs\n",
    "\n",
    "if os.path.exists(\"./data.pkl\"):\n",
    "    with open(\"./data.pkl\", 'rb') as fp:\n",
    "        rt_iot2022 = pickle.load(fp)\n",
    "else:\n",
    "    rt_iot2022 = fetch_ucirepo(id=942)\n",
    "    with open(\"./data.pkl\", 'wb') as fp:\n",
    "        pickle.dump(rt_iot2022, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1495988/875652746.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if unique[i] <= 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing bwd_URG_flag_count\n"
     ]
    }
   ],
   "source": [
    "# Remove axes that don't contribute to data, and get labels\n",
    "features = rt_iot2022.data.features\n",
    "targets = rt_iot2022.data.targets\n",
    "\n",
    "unique = features.nunique(axis=0)\n",
    "for i in range(len(unique)):\n",
    "    if unique[i] <= 1:\n",
    "        print(\"Removing\", features.axes[1][i])\n",
    "        del features[features.axes[1][i]]\n",
    "# bwd_URG_flag count is always the same, usually removed\n",
    "\n",
    "# Get labels for data (attack or normal behavior)\n",
    "normal_patterns = [\"MQTT_Publish\", \"Thing_Speak\", \"Wipro_bulb\", \"Amazon-Alexa\"]\n",
    "y_bool = [int(x in normal_patterns) for x in targets.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to numerical\n",
    "unique_service = list(features[\"service\"].unique())\n",
    "unique_proto = list(features[\"proto\"].unique())\n",
    "for i in range(len(features[\"service\"])):\n",
    "    features.loc[i, \"service\"] = unique_service.index(features[\"service\"][i])\n",
    "    features.loc[i, \"proto\"] = unique_proto.index(features[\"proto\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123117, 82)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit all data from -1 to 1\n",
    "def normalize_axis(axis):\n",
    "    return (axis - axis.min()) / (axis.max() - axis.min())\n",
    "\n",
    "X = features.values\n",
    "X = X.T\n",
    "for idx in range(len(X)):\n",
    "    X[idx] = normalize_axis(X[idx]) \n",
    "X = X.T\n",
    "X = X.astype('float64')\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous_vars = rt_iot2022.variables[rt_iot2022.variables['type'] == \"Continuous\"]['name'].tolist()\n",
    "# features = features[continuous_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test sets\n",
    "X = features.values\n",
    "y = np.array(y_bool)\n",
    "np.random.seed(1)\n",
    "\n",
    "test_split = .2\n",
    "test_samples = int(len(X) * test_split)\n",
    "perm  = np.random.permutation(len(X))\n",
    "X = X[perm]\n",
    "y = y[perm]\n",
    "\n",
    "x_test = X[0:test_samples]\n",
    "y_test = y[0:test_samples]\n",
    "x_train  = X[test_samples:]\n",
    "y_train  = y[test_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data by class\n",
    "def separate_by_class(data, labels):\n",
    "    separated = dict()\n",
    "    for i in range(len(data)):\n",
    "        vector = data[i]\n",
    "        if labels[i] not in separated:\n",
    "            separated[labels[i]] = list()    \n",
    "        separated[labels[i]].append(vector)\n",
    "    return separated\n",
    "\n",
    "separated_train = separate_by_class(x_train, y_train)\n",
    "separated_test = separate_by_class(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical measures\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stddev(numbers):\n",
    "    variance = sum([(x - mean(numbers))**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = []\n",
    "    for column in zip(*dataset):\n",
    "        # changed to numpy versions for efficency reasons (50 mins vs a few seconds)\n",
    "        column = np.array(column)\n",
    "        summaries.append([np.mean(column), np.std(column), len(column)])\n",
    "    return summaries\n",
    "\n",
    "# pass in the separated dataset\n",
    "def summarize_classwise(dataset):\n",
    "    summaries = dict()\n",
    "    for classy, rows in dataset.items():\n",
    "        summaries[classy] = summarize(rows)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_test = summarize_classwise(separated_test)\n",
    "summarized_train = summarize_classwise(separated_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian prob dist calculation\n",
    "def calc_prob(x, mean, std):\n",
    "        exponential = exp(-((x-mean)**2 / (2 * std**2)))\n",
    "        return (1 / (sqrt(2 * pi) * std)) * exponential\n",
    "\n",
    "\n",
    "def calc_class_prob(summaries, row):\n",
    "    probs = dict()\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    for i, val in summaries.items():\n",
    "        probs[i] = summaries[i][0][2] / float(total_rows)\n",
    "        for j in range(len(val)):\n",
    "            mean, std, _ = val[j]\n",
    "            probs[i] *= calc_prob(row[j], mean, std)\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all values with a standard deviation of zero in train\n",
    "std_zero = []\n",
    "for i in range(len(summarized_train[0])):\n",
    "    if summarized_train[0][i][1] == 0 or summarized_train[1][i][1] == 0:\n",
    "        std_zero.append(i)\n",
    "\n",
    "x_test = np.transpose(x_test)\n",
    "x_train = np.transpose(x_train)\n",
    "\n",
    "\n",
    "for i in reversed(range(len(std_zero))):\n",
    "    summarized_test[0].pop(std_zero[i])\n",
    "    summarized_test[1].pop(std_zero[i])\n",
    "    summarized_train[0].pop(std_zero[i])\n",
    "    summarized_train[1].pop(std_zero[i])\n",
    "    x_test = np.delete(x_test, std_zero[i], 0)\n",
    "    x_train = np.delete(x_train, std_zero[i], 0)\n",
    "\n",
    "x_test = np.transpose(x_test)\n",
    "x_train = np.transpose(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 2.6572866439819336 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "predicted = []\n",
    "for i in x_test:\n",
    "    probs = calc_class_prob(summarized_train, i)\n",
    "    if probs[0] > probs[1]:\n",
    "        predicted.append(0)\n",
    "    else:\n",
    "        predicted.append(1)\n",
    "\n",
    "print(f\"Finished in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes accuracy is: 0.9292531373106445\n",
      "Balanced Acc is:  0.7955806924117641\n"
     ]
    }
   ],
   "source": [
    "true_positive = 0\n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 1:\n",
    "        if predicted[i] == y_test[i]:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    elif predicted[i] == 0:\n",
    "        if predicted[i] == y_test[i]:\n",
    "            true_negative += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "\n",
    "pos_acc = true_positive / (true_positive + false_positive)\n",
    "neg_acc = true_negative / (true_negative + false_negative)\n",
    "\n",
    "print(\"Naive bayes accuracy is:\", (true_positive + true_negative)/len(predicted))\n",
    "print(\"Balanced Acc is: \", (pos_acc+neg_acc)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected  20380  attacks from  24623\n",
      "Incorrectly detected  19  attacks from  24623\n",
      "Missed  1723  attacks from  24623\n",
      "Correctly asserted  2501  packets as non harmful\n"
     ]
    }
   ],
   "source": [
    "# y_bool of positive is normal behavior, negative is attack packet\n",
    "print(\"Detected \", true_negative, \" attacks from \", len(predicted))\n",
    "print(\"Incorrectly detected \", false_negative, \" attacks from \", len(predicted))\n",
    "\n",
    "print(\"Missed \", false_positive, \" attacks from \", len(predicted))\n",
    "print(\"Correctly asserted \", true_positive, \" packets as non harmful\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvpath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
